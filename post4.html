<!-- === ROBOTS.TXT SECTION === -->
<section class="tutorial">
  <h1>How to Add a robots.txt to Your GitHub Pages Site</h1>

  <p><strong>Step 1:</strong> Create a file named <code>robots.txt</code> in the root of your repository (same folder as <code>index.html</code>).</p>

  <p><strong>Step 2:</strong> Add rules to control search engine access. Example:</p>

  <pre><code>User-agent: *
Disallow: /private/
Allow: /
Sitemap: https://yourusername.github.io/sitemap.xml
</code></pre>

  <p><strong>Step 3:</strong> Save and push the file to GitHub Pages.</p>

  <p><strong>Step 4:</strong> Verify it by opening:
  <a href="https://yourusername.github.io/robots.txt" target="_blank">https://yourusername.github.io/robots.txt</a></p>

  <p><em>Screenshot placeholder: robots.txt file visible in browser</em></p>

  <p><strong>Tip:</strong> Use robots.txt to control which pages search engines can index and to point to your sitemap for better SEO.</p>
</section>
